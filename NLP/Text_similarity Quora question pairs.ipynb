{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a02dfe1",
   "metadata": {},
   "source": [
    "Quora question pairs dataset is available on Kaggle. \n",
    "Goal is to identify which questions asked on Quora are duplicates of questions that have already been asked.\n",
    "\n",
    "#text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddb573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18baec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "664ba206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import Levenshtein\n",
    "from fuzzywuzzy import fuzz\n",
    "import jellyfish\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "\n",
    "import gensim\n",
    "from gensim import matutils\n",
    "from sklearn.pipeline import Pipeline\n",
    "import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e7c85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef, confusion_matrix, f1_score, log_loss, roc_auc_score,\\\n",
    "                            plot_roc_curve, accuracy_score, roc_curve, fbeta_score, ConfusionMatrixDisplay,\\\n",
    "                            precision_score, classification_report, balanced_accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, RandomizedSearchCV,\\\n",
    "                                    cross_validate,cross_val_score, RepeatedStratifiedKFold\n",
    "from joblib import parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.decomposition import TruncatedSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5768812",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option('max_colwidth', 256)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b948554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b3b3bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a213b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper func\n",
    "def get_scores(y_true, y_pred_probs, thresh = 0.5):\n",
    "    y_pred = [1 if i > thresh else 0 for i in y_pred_probs]\n",
    "    mcc_score = matthews_corrcoef(y_true, y_pred)\n",
    "    fscore = f1_score(y_true, y_pred, average='binary')\n",
    "    logloss = log_loss(y_true, y_pred_probs)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f2 = fbeta_score(y_true, y_pred, beta=2.0, average='binary')\n",
    "    print(f\"The accuracy is {round(acc*100, 3)}%\")\n",
    "    print(f\"The MCC Score is {mcc_score} \")\n",
    "    print(f\"The F1 Score is {fscore}\")\n",
    "    print(f\"The F2 Score is {f2}\")\n",
    "    print(f\"The Logloss is {logloss}\")\n",
    "    print(\"-\"*50)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = round(fp/(fp+tn),3)\n",
    "    fnr = round((fn/(fn+tp)), 3)\n",
    "    print(cm)\n",
    "    print(\"-\"*50)\n",
    "    print(f\"The FPR is {fpr*100}%\")\n",
    "    print(f\"The FNR is {fnr*100}%\")\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd11a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca5f53c6",
   "metadata": {},
   "source": [
    "### reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab7d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9fb1a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d33ebe7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>34995</td>\n",
       "      <td>64020</td>\n",
       "      <td>64021</td>\n",
       "      <td>What is mystore99.com?</td>\n",
       "      <td>What is Shortfeeds.com?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36414</th>\n",
       "      <td>36414</td>\n",
       "      <td>66408</td>\n",
       "      <td>66409</td>\n",
       "      <td>Is Nokia Takeover a management buyout?</td>\n",
       "      <td>Why did Nokia fail?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268210</th>\n",
       "      <td>268210</td>\n",
       "      <td>385717</td>\n",
       "      <td>385718</td>\n",
       "      <td>What is a bad college GPA?</td>\n",
       "      <td>Working as a produce clerk?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                               question1  \\\n",
       "34995    34995   64020   64021                  What is mystore99.com?   \n",
       "36414    36414   66408   66409  Is Nokia Takeover a management buyout?   \n",
       "268210  268210  385717  385718              What is a bad college GPA?   \n",
       "\n",
       "                          question2  is_duplicate  \n",
       "34995       What is Shortfeeds.com?             0  \n",
       "36414           Why did Nokia fail?             0  \n",
       "268210  Working as a produce clerk?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232a2932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404290 non-null  int64 \n",
      " 1   qid1          404290 non-null  int64 \n",
      " 2   qid2          404290 non-null  int64 \n",
      " 3   question1     404289 non-null  object\n",
      " 4   question2     404288 non-null  object\n",
      " 5   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "questions_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36dde4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed2aa187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = questions_df.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "734aa9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 120017 to 251634\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            20000 non-null  int64 \n",
      " 1   qid1          20000 non-null  int64 \n",
      " 2   qid2          20000 non-null  int64 \n",
      " 3   question1     20000 non-null  object\n",
      " 4   question2     20000 non-null  object\n",
      " 5   is_duplicate  20000 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd72b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12682\n",
       "1     7318\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e046ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    63.41\n",
       "1    36.59\n",
       "Name: is_duplicate, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['is_duplicate'].value_counts()/df['is_duplicate'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d33e88bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['is_duplicate'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05af74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['question1', 'question2', 'is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "680936c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d16d2f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>254510</th>\n",
       "      <td>Which is the best 3D Printer in India and where can I buy?</td>\n",
       "      <td>What is the best 3D printer to buy in India?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         question1  \\\n",
       "254510  Which is the best 3D Printer in India and where can I buy?   \n",
       "\n",
       "                                           question2  \n",
       "254510  What is the best 3D printer to buy in India?  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[['question1', 'question2']].sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2293027b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df[['question1', 'question2']]\n",
    "y = new_df[['is_duplicate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171295bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c82404b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data before performing any prepsocessing etc, to avoid any data leakage\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.15, stratify = y, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858dcaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA was performed in other notebook, will share that too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67245c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82ed52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    '''Make text lowercase, remove text in quotes, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\\".*?\\\"', ' ', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
    "    text = re.sub('[‘’“”…]', ' ', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text=re.sub(r\"[~.,%/:;?_&+*=—!-]\",' ',text)\n",
    "    \n",
    "     # Replace certain special characters with their string equivalents\n",
    "    text = text.replace('%', ' percent')\n",
    "    text = text.replace('$', ' dollar ')\n",
    "    text = text.replace('₹', ' rupee ')\n",
    "    text = text.replace('€', ' euro ')\n",
    "    text = text.replace('@', ' at ')\n",
    "    \n",
    "    return text\n",
    "\n",
    "contraction_dict = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"}\n",
    "\n",
    "# Regular expression for finding contractions\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "def expand_cntractns (text,contraction_dict = contraction_dict):\n",
    "    def rep(match):\n",
    "        return contraction_dict[match.group(0)]\n",
    "    return contractions_re.sub(rep, text)\n",
    "\n",
    "\n",
    "#removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    cleaned_column = ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
    "    \n",
    "    return cleaned_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22383db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "005595cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocess(text):\n",
    "    \"\"\"Apply multiple cleaning functions to the text\"\"\"\n",
    "    text = expand_cntractns(text)\n",
    "    text = cleaning_text(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ce84e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train['question1'] = X_train['question1'].apply(text_preprocess)\n",
    "X_train['question2'] = X_train['question2'].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "853fd4f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388272</th>\n",
       "      <td>what are the best resources when applying for a medicine graduate degree</td>\n",
       "      <td>what are the best resources when applying for a music graduate degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219334</th>\n",
       "      <td>what can i use java for</td>\n",
       "      <td>what programs can java be used for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        question1  \\\n",
       "388272  what are the best resources when applying for a medicine graduate degree    \n",
       "219334                                                   what can i use java for    \n",
       "\n",
       "                                                                     question2  \n",
       "388272  what are the best resources when applying for a music graduate degree   \n",
       "219334                                     what programs can java be used for   "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['question1', 'question2']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a409c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token based feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d78ff789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return len(w1 & w2)\n",
    "\n",
    "\n",
    "def total_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e39587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance\n",
    "\n",
    "def fetch_length_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    length_features = [0.0]*3\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "    \n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    \n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "    \n",
    "    return length_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f55bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_feats(df):\n",
    "    \n",
    "    df['len_q1'] = df['question1'].str.len() \n",
    "    df['len_q2'] = df['question2'].str.len()\n",
    "\n",
    "    df['q1_num_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "    df['q2_num_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))\n",
    "    df['common_words'] = df.apply(common_words, axis=1)\n",
    "    df['word_total'] = df.apply(total_words, axis=1)\n",
    "    df['word_share'] = round(df['common_words']/df['word_total'], 2)\n",
    "    \n",
    "    length_features = df.apply(fetch_length_features, axis=1)\n",
    "\n",
    "    df['abs_len_diff'] = list(map(lambda x: x[0], length_features))\n",
    "    df['mean_len'] = list(map(lambda x: x[1], length_features))\n",
    "    df['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ac4df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_token_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    SAFE_DIV = 0.0001 \n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "    \n",
    "    token_features = [0.0]*8\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9384bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_token_feats(df):\n",
    "    token_features = df.apply(fetch_token_features, axis=1)\n",
    "\n",
    "    df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "    df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "    df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "    df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "    df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "    df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "    df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "    df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc0e4b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = token_feats(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3dfc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = more_token_feats(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acb70dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>common_words</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388272</th>\n",
       "      <td>what are the best resources when applying for a medicine graduate degree</td>\n",
       "      <td>what are the best resources when applying for a music graduate degree</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219334</th>\n",
       "      <td>what can i use java for</td>\n",
       "      <td>what programs can java be used for</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        question1  \\\n",
       "388272  what are the best resources when applying for a medicine graduate degree    \n",
       "219334                                                   what can i use java for    \n",
       "\n",
       "                                                                     question2  \\\n",
       "388272  what are the best resources when applying for a music graduate degree    \n",
       "219334                                     what programs can java be used for    \n",
       "\n",
       "        len_q1  len_q2  q1_num_words  q2_num_words  common_words  word_total  \\\n",
       "388272      73      70            13            13            12          26   \n",
       "219334      24      35             7             8             5          15   \n",
       "\n",
       "        word_share  abs_len_diff  mean_len  longest_substr_ratio   cwc_min  \\\n",
       "388272        0.46           0.0      12.0              0.690141  0.833319   \n",
       "219334        0.33           1.0       6.5              0.240000  0.499975   \n",
       "\n",
       "         cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "388272  0.833319  0.999983  0.999983  0.916659  0.916659           1.0   \n",
       "219334  0.333322  0.749981  0.749981  0.666656  0.571420           1.0   \n",
       "\n",
       "        first_word_eq  \n",
       "388272            1.0  \n",
       "219334            1.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "871de5d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76554bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "350c8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#func to calculate jaccard similairty\n",
    "def jaccard_similarity(text1, text2):\n",
    "    set1 = set(str(text1).split())\n",
    "    set2 = set(str(text2).split())\n",
    "    \n",
    "    if len(set1.union(set2)) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        #jaccard similarity\n",
    "        return len(set1.intersection(set2)) / len(set1.union(set2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b7f1459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similairty_features(row):\n",
    "    \n",
    "    q1_ = row['question1']\n",
    "    q2_ = row['question2']\n",
    "    \n",
    "    t_features = [0.0]*8\n",
    "    \n",
    "    q1 = remove_stopwords(q1_)\n",
    "    q2 = remove_stopwords(q2_)\n",
    "    \n",
    "    # fuzz_ratio\n",
    "    t_features[0] = fuzz.QRatio(q1, q2)\n",
    "\n",
    "    # fuzz_partial_ratio\n",
    "    t_features[1] = fuzz.partial_ratio(q1, q2)\n",
    "\n",
    "    # token_sort_ratio\n",
    "    t_features[2] = fuzz.token_sort_ratio(q1, q2)\n",
    "\n",
    "    # token_set_ratio\n",
    "    t_features[3] = fuzz.token_set_ratio(q1, q2)\n",
    "    \n",
    "    # levenshtein\n",
    "    t_features[4] = Levenshtein.distance(str(q1), str(q2))\n",
    "    \n",
    "     # jarowinkler\n",
    "    t_features[5] = jellyfish.jaro_winkler(str(q1), str(q2))\n",
    "    \n",
    "     # jaccard_set_ratio\n",
    "    t_features[6] = jaccard_similarity(q1_, q2_)\n",
    "    \n",
    "    #wratio    \n",
    "    t_features[7] = fuzz.WRatio(q1, q2)\n",
    "    \n",
    "    return t_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442999c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2985a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_cols(df):\n",
    "    \n",
    "    sim_features = df.apply(get_similairty_features, axis=1)\n",
    "\n",
    "    # Creating new feature columns for fuzzy features\n",
    "    df['fuzz_ratio'] = list(map(lambda x: x[0], sim_features))\n",
    "    df['fuzz_partial_ratio'] = list(map(lambda x: x[1], sim_features))\n",
    "    df['token_sort_ratio'] = list(map(lambda x: x[2], sim_features))\n",
    "    df['token_set_ratio'] = list(map(lambda x: x[3], sim_features))\n",
    "    df['leven_dis'] = list(map(lambda x: x[4], sim_features))\n",
    "    df['jaro_winkler'] = list(map(lambda x: x[5], sim_features))\n",
    "    df['jaccard_sim'] = list(map(lambda x: x[6], sim_features))\n",
    "    df['wratio'] = list(map(lambda x: x[7], sim_features))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82204cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "860f4485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = similarity_cols(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cec42ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 28)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f14cd610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>common_words</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>leven_dis</th>\n",
       "      <th>jaro_winkler</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>wratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>388272</th>\n",
       "      <td>what are the best resources when applying for a medicine graduate degree</td>\n",
       "      <td>what are the best resources when applying for a music graduate degree</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>0.933068</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219334</th>\n",
       "      <td>what can i use java for</td>\n",
       "      <td>what programs can java be used for</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.666656</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>67</td>\n",
       "      <td>13</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        question1  \\\n",
       "388272  what are the best resources when applying for a medicine graduate degree    \n",
       "219334                                                   what can i use java for    \n",
       "\n",
       "                                                                     question2  \\\n",
       "388272  what are the best resources when applying for a music graduate degree    \n",
       "219334                                     what programs can java be used for    \n",
       "\n",
       "        len_q1  len_q2  q1_num_words  q2_num_words  common_words  word_total  \\\n",
       "388272      73      70            13            13            12          26   \n",
       "219334      24      35             7             8             5          15   \n",
       "\n",
       "        word_share  abs_len_diff  mean_len  longest_substr_ratio   cwc_min  \\\n",
       "388272        0.46           0.0      12.0              0.690141  0.833319   \n",
       "219334        0.33           1.0       6.5              0.240000  0.499975   \n",
       "\n",
       "         cwc_max   csc_min   csc_max   ctc_min   ctc_max  last_word_eq  \\\n",
       "388272  0.833319  0.999983  0.999983  0.916659  0.916659           1.0   \n",
       "219334  0.333322  0.749981  0.749981  0.666656  0.571420           1.0   \n",
       "\n",
       "        first_word_eq  fuzz_ratio  fuzz_partial_ratio  token_sort_ratio  \\\n",
       "388272            1.0          92                  89                92   \n",
       "219334            1.0          46                  75                62   \n",
       "\n",
       "        token_set_ratio  leven_dis  jaro_winkler  jaccard_sim  wratio  \n",
       "388272               93          5      0.933068     0.846154      92  \n",
       "219334               67         13      0.527778     0.444444      86  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16ffd0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>common_words</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>leven_dis</th>\n",
       "      <th>jaro_winkler</th>\n",
       "      <th>jaccard_sim</th>\n",
       "      <th>wratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.896471</td>\n",
       "      <td>59.379294</td>\n",
       "      <td>12.699765</td>\n",
       "      <td>12.927706</td>\n",
       "      <td>5.931471</td>\n",
       "      <td>22.822765</td>\n",
       "      <td>0.271219</td>\n",
       "      <td>3.690706</td>\n",
       "      <td>10.993059</td>\n",
       "      <td>0.391651</td>\n",
       "      <td>0.589177</td>\n",
       "      <td>0.458201</td>\n",
       "      <td>0.568939</td>\n",
       "      <td>0.431822</td>\n",
       "      <td>0.556063</td>\n",
       "      <td>0.431108</td>\n",
       "      <td>0.307765</td>\n",
       "      <td>0.513118</td>\n",
       "      <td>61.977471</td>\n",
       "      <td>70.034765</td>\n",
       "      <td>64.361824</td>\n",
       "      <td>74.611176</td>\n",
       "      <td>24.050706</td>\n",
       "      <td>0.746915</td>\n",
       "      <td>0.369689</td>\n",
       "      <td>76.774471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.475111</td>\n",
       "      <td>32.230883</td>\n",
       "      <td>6.337961</td>\n",
       "      <td>7.054677</td>\n",
       "      <td>3.089572</td>\n",
       "      <td>8.260150</td>\n",
       "      <td>0.117621</td>\n",
       "      <td>4.543751</td>\n",
       "      <td>4.906693</td>\n",
       "      <td>0.232345</td>\n",
       "      <td>0.313879</td>\n",
       "      <td>0.277373</td>\n",
       "      <td>0.336674</td>\n",
       "      <td>0.298335</td>\n",
       "      <td>0.267504</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.461582</td>\n",
       "      <td>0.499843</td>\n",
       "      <td>20.603456</td>\n",
       "      <td>20.155858</td>\n",
       "      <td>19.954459</td>\n",
       "      <td>21.614604</td>\n",
       "      <td>20.290148</td>\n",
       "      <td>0.149981</td>\n",
       "      <td>0.244520</td>\n",
       "      <td>18.297856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.374995</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.199996</td>\n",
       "      <td>0.363633</td>\n",
       "      <td>0.235293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.635040</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.346939</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.415227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.712715</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>86.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.615380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.885005</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>309.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             len_q1        len_q2  q1_num_words  q2_num_words  common_words  \\\n",
       "count  17000.000000  17000.000000  17000.000000  17000.000000  17000.000000   \n",
       "mean      58.896471     59.379294     12.699765     12.927706      5.931471   \n",
       "std       29.475111     32.230883      6.337961      7.054677      3.089572   \n",
       "min        1.000000      1.000000      2.000000      2.000000      0.000000   \n",
       "25%       39.000000     38.000000      9.000000      9.000000      4.000000   \n",
       "50%       51.000000     50.000000     11.000000     11.000000      6.000000   \n",
       "75%       71.000000     71.000000     15.000000     15.000000      7.000000   \n",
       "max      309.000000    334.000000     83.000000     97.000000     32.000000   \n",
       "\n",
       "         word_total    word_share  abs_len_diff      mean_len  \\\n",
       "count  17000.000000  17000.000000  17000.000000  17000.000000   \n",
       "mean      22.822765      0.271219      3.690706     10.993059   \n",
       "std        8.260150      0.117621      4.543751      4.906693   \n",
       "min        6.000000      0.000000      0.000000      0.000000   \n",
       "25%       17.000000      0.180000      1.000000      8.000000   \n",
       "50%       21.000000      0.270000      2.000000     10.000000   \n",
       "75%       27.000000      0.360000      5.000000     13.000000   \n",
       "max       90.000000      0.500000     45.000000     56.500000   \n",
       "\n",
       "       longest_substr_ratio       cwc_min       cwc_max       csc_min  \\\n",
       "count          17000.000000  17000.000000  17000.000000  17000.000000   \n",
       "mean               0.391651      0.589177      0.458201      0.568939   \n",
       "std                0.232345      0.313879      0.277373      0.336674   \n",
       "min                0.000000      0.000000      0.000000      0.000000   \n",
       "25%                0.212766      0.374995      0.249997      0.333322   \n",
       "50%                0.346939      0.666644      0.499975      0.599988   \n",
       "75%                0.533333      0.833319      0.666644      0.833319   \n",
       "max                0.992481      0.999993      0.999993      0.999993   \n",
       "\n",
       "            csc_max       ctc_min       ctc_max  last_word_eq  first_word_eq  \\\n",
       "count  17000.000000  17000.000000  17000.000000  17000.000000   17000.000000   \n",
       "mean       0.431822      0.556063      0.431108      0.307765       0.513118   \n",
       "std        0.298335      0.267504      0.247000      0.461582       0.499843   \n",
       "min        0.000000      0.000000      0.000000      0.000000       0.000000   \n",
       "25%        0.199996      0.363633      0.235293      0.000000       0.000000   \n",
       "50%        0.399992      0.571420      0.415227      0.000000       1.000000   \n",
       "75%        0.666644      0.777769      0.615380      1.000000       1.000000   \n",
       "max        0.999992      0.999995      0.999995      1.000000       1.000000   \n",
       "\n",
       "         fuzz_ratio  fuzz_partial_ratio  token_sort_ratio  token_set_ratio  \\\n",
       "count  17000.000000        17000.000000      17000.000000     17000.000000   \n",
       "mean      61.977471           70.034765         64.361824        74.611176   \n",
       "std       20.603456           20.155858         19.954459        21.614604   \n",
       "min        0.000000            0.000000          0.000000         0.000000   \n",
       "25%       45.000000           54.000000         50.000000        60.000000   \n",
       "50%       61.000000           70.000000         64.000000        78.000000   \n",
       "75%       78.000000           86.000000         79.000000        94.000000   \n",
       "max      100.000000          100.000000        100.000000       100.000000   \n",
       "\n",
       "          leven_dis  jaro_winkler   jaccard_sim        wratio  \n",
       "count  17000.000000  17000.000000  17000.000000  17000.000000  \n",
       "mean      24.050706      0.746915      0.369689     76.774471  \n",
       "std       20.290148      0.149981      0.244520     18.297856  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        9.000000      0.635040      0.178571     66.000000  \n",
       "50%       19.000000      0.712715      0.333333     86.000000  \n",
       "75%       34.000000      0.885005      0.538462     88.000000  \n",
       "max      188.000000      1.000000      1.000000    100.000000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a507222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question1', 'question2', 'len_q1', 'len_q2', 'q1_num_words',\n",
       "       'q2_num_words', 'common_words', 'word_total', 'word_share',\n",
       "       'abs_len_diff', 'mean_len', 'longest_substr_ratio', 'cwc_min',\n",
       "       'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max', 'last_word_eq',\n",
       "       'first_word_eq', 'fuzz_ratio', 'fuzz_partial_ratio', 'token_sort_ratio',\n",
       "       'token_set_ratio', 'leven_dis', 'jaro_winkler', 'jaccard_sim',\n",
       "       'wratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7936a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats = ['len_q1', 'len_q2',\n",
    "       'q1_num_words', 'q2_num_words', 'common_words', 'word_total',\n",
    "       'word_share', 'abs_len_diff', 'mean_len', 'longest_substr_ratio',\n",
    "       'cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctc_min', 'ctc_max',\n",
    "       'last_word_eq', 'first_word_eq', 'fuzz_ratio', 'fuzz_partial_ratio',\n",
    "       'token_sort_ratio', 'token_set_ratio', 'leven_dis', 'jaro_winkler',\n",
    "       'jaccard_sim', 'wratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad39e61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "new_df_2 = MinMaxScaler().fit_transform(new_df[numeric_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7972ac3",
   "metadata": {},
   "source": [
    "### only numeric feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43415e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_num = xgb.XGBClassifier(max_depth=50, n_estimators=300, learning_rate=0.2, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, subsample=0.8, eval_metric = 'logloss').fit(new_df_2, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9533183f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test['question1'] = X_test['question1'].apply(text_preprocess)\n",
    "X_test['question2'] = X_test['question2'].apply(text_preprocess)\n",
    "\n",
    "#token based feats\n",
    "X_test_ = token_feats(X_test)\n",
    "\n",
    "X_test_ = more_token_feats(X_test_)\n",
    "\n",
    "#sim based feats\n",
    "X_test_ = similarity_cols(X_test)\n",
    "\n",
    "X_test_ = MinMaxScaler().fit_transform(X_test_[numeric_feats])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10409291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 72.2%\n",
      "The MCC Score is 0.39268522036685577 \n",
      "The F1 Score is 0.6066037735849056\n",
      "The F2 Score is 0.5938308090136681\n",
      "The Logloss is 0.5317060034299939\n",
      "--------------------------------------------------\n",
      "[[1523  379]\n",
      " [ 455  643]]\n",
      "--------------------------------------------------\n",
      "The FPR is 19.900000000000002%\n",
      "The FNR is 41.4%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_probs = xgb_clf_num.predict_proba(X_test_)[:,1]\n",
    "get_scores(y_test, test_probs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6fc40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ae0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b9bb95",
   "metadata": {},
   "source": [
    "### only tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43d2747f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=5000, stop_words=&#x27;english&#x27;,\n",
       "                tokenizer=&lt;function word_tokenize at 0x13cf08940&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=5000, stop_words=&#x27;english&#x27;,\n",
       "                tokenizer=&lt;function word_tokenize at 0x13cf08940&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=5000, stop_words='english',\n",
       "                tokenizer=<function word_tokenize at 0x13cf08940>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(analyzer=\"word\", tokenizer = nltk.word_tokenize, stop_words='english', max_features=5000)\n",
    "tfidf_vec.fit(pd.concat((new_df['question1'], new_df['question2'])).unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99723a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainq1_trans = tfidf_vec.transform(new_df['question1'].values)\n",
    "trainq2_trans = tfidf_vec.transform(new_df['question2'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb9ca662",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_w = hstack((trainq1_trans,trainq2_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a571aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500, n_iter=20, random_state=12)\n",
    "trunc_tfidf_w = svd.fit_transform(tfidf_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3244a64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 800)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_tfidf_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf0b68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_tfidf = xgb.XGBClassifier(max_depth=50, n_estimators=300, learning_rate=0.2, colsample_bytree=.7, gamma=0, \n",
    "                            reg_alpha=4, objective='binary:logistic', eta=0.3, subsample=0.8,\n",
    "                            eval_metric = 'logloss').fit(trunc_tfidf_w, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cdb0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "X_test['question1'] = X_test['question1'].apply(text_preprocess)\n",
    "X_test['question2'] = X_test['question2'].apply(text_preprocess)\n",
    "\n",
    "\n",
    "testq1_trans = tfidf_vec.transform(X_test['question1'].values)\n",
    "testq2_trans = tfidf_vec.transform(X_test['question2'].values)\n",
    "\n",
    "tfidf_test_ = hstack((testq1_trans, testq2_trans))\n",
    "\n",
    "trunctest_tfidf_ = svd.fit_transform(tfidf_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ffb8bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 61.967%\n",
      "The MCC Score is 0.08247954788804163 \n",
      "The F1 Score is 0.2810333963453056\n",
      "The F2 Score is 0.2284367957385781\n",
      "The Logloss is 0.7089732608828538\n",
      "--------------------------------------------------\n",
      "[[1636  266]\n",
      " [ 875  223]]\n",
      "--------------------------------------------------\n",
      "The FPR is 14.000000000000002%\n",
      "The FNR is 79.7%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_probs = xgb_clf_tfidf.predict_proba(trunctest_tfidf_)[:,1]\n",
    "get_scores(y_test, test_probs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83ee172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af9a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37b1b8b1",
   "metadata": {},
   "source": [
    "### numeric feats+tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "908cb390",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_2 = np.hstack((new_df_2, trunc_tfidf_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "506cf39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17000, 526)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607eb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters selected based on the performance from the validation data, better is to perform cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9f6b56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(max_depth=50, n_estimators=300, learning_rate=0.2, colsample_bytree=.7, gamma=0, \n",
    "                            reg_alpha=4, objective='binary:logistic', eta=0.3, subsample=0.8,\n",
    "                            eval_metric = 'logloss').fit(X_train_2, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4c60d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93f2df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing test data\n",
    "X_test['question1'] = X_test['question1'].apply(text_preprocess)\n",
    "X_test['question2'] = X_test['question2'].apply(text_preprocess)\n",
    "\n",
    "#token based feats\n",
    "X_test_ = token_feats(X_test)\n",
    "\n",
    "X_test_ = more_token_feats(X_test_)\n",
    "\n",
    "#sim based feats\n",
    "X_test_ = similarity_cols(X_test)\n",
    "\n",
    "testq1_trans = tfidf_vec.transform(X_test['question1'].values)\n",
    "testq2_trans = tfidf_vec.transform(X_test['question2'].values)\n",
    "\n",
    "tfidf_test_w = hstack((testq1_trans, testq2_trans))\n",
    "\n",
    "trunctest_tfidf_w = svd.fit_transform(tfidf_test_w)\n",
    "\n",
    "X_test_ = MinMaxScaler().fit_transform(X_test_[numeric_feats])\n",
    "X_test_2 = np.hstack((X_test_, trunctest_tfidf_w))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4ac0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 526)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e71b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = xgb_clf.predict_proba(X_test_2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2da99338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 71.133%\n",
      "The MCC Score is 0.3869981399664826 \n",
      "The F1 Score is 0.6181657848324514\n",
      "The F2 Score is 0.6301690039554118\n",
      "The Logloss is 0.5342493496769785\n",
      "--------------------------------------------------\n",
      "[[1433  469]\n",
      " [ 397  701]]\n",
      "--------------------------------------------------\n",
      "The FPR is 24.7%\n",
      "The FNR is 36.199999999999996%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, test_probs, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e393e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "393fa008",
   "metadata": {},
   "source": [
    "### numeric feats+tfidf with ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6eca3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngram\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', ngram_range=(2,3), tokenizer = nltk.word_tokenize,\n",
    "                                   stop_words='english',  max_features=5000)\n",
    "tfidf_vect_ngram.fit(pd.concat((new_df['question1'], new_df['question2'])).unique())\n",
    "\n",
    "\n",
    "trainq1_ngram = tfidf_vect_ngram.transform(new_df['question1'].values)\n",
    "trainq2_ngram = tfidf_vect_ngram.transform(new_df['question2'].values)\n",
    "\n",
    "tfidf_ngram = hstack((trainq1_ngram, trainq2_ngram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "057bddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500, n_iter=20, random_state=12)\n",
    "trunc_tfidf_ngram = svd.fit_transform(tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ce089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "607bff21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ngram = np.hstack((new_df_2, trunc_tfidf_ngram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f34cb4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_model_ngram = xgb.XGBClassifier(max_depth=50, n_estimators=300, learning_rate=0.2, colsample_bytree=.7, gamma=0,\n",
    "                                    reg_alpha=4, objective='binary:logistic', eta=0.3, subsample=0.8,\n",
    "                                    eval_metric = 'logloss').fit(X_ngram, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08555140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "testq1_ngram = tfidf_vect_ngram.transform(X_test['question1'].values)\n",
    "testq2_ngram = tfidf_vect_ngram.transform(X_test['question2'].values)\n",
    "\n",
    "tfidf_test_ngram = hstack((testq1_ngram, testq2_ngram))\n",
    "\n",
    "trunctest_tfidf_ngram = svd.fit_transform(tfidf_test_ngram)\n",
    "\n",
    "X_test_ngram = np.hstack((X_test_, trunctest_tfidf_ngram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7891e15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 526)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ngram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3c68be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_ngram = xgb_model_ngram.predict_proba(X_test_ngram)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c5b4442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 72.133%\n",
      "The MCC Score is 0.38515516711508613 \n",
      "The F1 Score is 0.5937803692905733\n",
      "The F2 Score is 0.570814648729447\n",
      "The Logloss is 0.5379027048442415\n",
      "--------------------------------------------------\n",
      "[[1553  349]\n",
      " [ 487  611]]\n",
      "--------------------------------------------------\n",
      "The FPR is 18.3%\n",
      "The FNR is 44.4%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, test_probs_ngram, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26579ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2d1d4a7",
   "metadata": {},
   "source": [
    "### numeric feats + Character Level TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8042e977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Character Level TF-IDF\n",
    "\n",
    "tfidf_char = TfidfVectorizer(analyzer='char', ngram_range=(2,3), stop_words='english',  max_features=5000,\n",
    "                             tokenizer = nltk.word_tokenize,)\n",
    "tfidf_char.fit(pd.concat((new_df['question1'], new_df['question2'])).unique())\n",
    "\n",
    "trainq1_char = tfidf_char.transform(new_df['question1'].values)\n",
    "trainq2_char = tfidf_char.transform(new_df['question2'].values)\n",
    "\n",
    "tfidf_char_ = hstack((trainq1_char, trainq2_char))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "220fd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500, n_iter=20, random_state=12)\n",
    "trunc_tfidf_char = svd.fit_transform(tfidf_char_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "01171a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_char = np.hstack((new_df_2, trunc_tfidf_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9abcd9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_char = xgb.XGBClassifier(max_depth=50, n_estimators=300, learning_rate=0.2, colsample_bytree=.7, \n",
    "                                   gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, subsample=0.8, \n",
    "                                   eval_metric = 'logloss').fit(X_char, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c699a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2d27868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "testq1_char = tfidf_char.transform(X_test['question1'].values)\n",
    "testq2_char = tfidf_char.transform(X_test['question2'].values)\n",
    "\n",
    "tfidf_test_char = hstack((testq1_char, testq2_char))\n",
    "\n",
    "trunctest_tfidf_char = svd.fit_transform(tfidf_test_char)\n",
    "\n",
    "X_test_char = np.hstack((X_test_, trunctest_tfidf_char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82de0d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 526)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_char.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c29d7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs_char = xgb_model_char.predict_proba(X_test_char)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e6fc06b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is 71.367%\n",
      "The MCC Score is 0.374971746160201 \n",
      "The F1 Score is 0.595764705882353\n",
      "The F2 Score is 0.5840560989112381\n",
      "The Logloss is 0.5457498975769085\n",
      "--------------------------------------------------\n",
      "[[1508  394]\n",
      " [ 465  633]]\n",
      "--------------------------------------------------\n",
      "The FPR is 20.7%\n",
      "The FNR is 42.3%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_scores(y_test, test_probs_char, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a118bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64a85982",
   "metadata": {},
   "source": [
    "### Based on F1 score and accuracy, out of all these models, the model with numeric feats and tfidf with words without using ngrams(2,3) but default 1 perfomed a little better than others. I chose F1 score to measure the performance because in thi sproblem I am more interested to use the model for similar pairs rather than disimilar ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b5187a",
   "metadata": {},
   "source": [
    "#### To further improve the model performance we can use cross validation to tune thehyperparameters. Also, can apply feature importance to remove the extra features or include more. Since in this example, we only used part of data but can test more using more data to have better performnce as F1 score of 61.8% and 72% accuracy aren't so great but a good start though.\n",
    "#### Deep learning models such as LSTM can also be tested as we have enough data.(I'll apply lstm in the future to test it further.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f320f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735708f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b0738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e3beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75539234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
